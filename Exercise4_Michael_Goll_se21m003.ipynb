{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if you want to use the GPU\n",
    "# device = 'gpu'\n",
    "# os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=' + device + ',floatX=float32'\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image # Pillow module\n",
    "#from theano import config\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(1) # we initialize a random seed here to make the experiments repeatable with same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Images from Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Dataset\n",
    "\n",
    "The dataset contains 50.000 datapoints of images classified into 10 classes:\n",
    "- airplane\n",
    "- automobile\n",
    "- bird \t\n",
    "- cat \n",
    "- deer \n",
    "- dog \n",
    "- frog \t\n",
    "- horse \n",
    "- ship \n",
    "- truck\n",
    "\n",
    "The images are 32 x 32 pixels in size and consists of 3 channels (rgb). Each class consists of 5000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source contains the files data_batch_1, data_batch_2, data_batch_3, data_batch_4, data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle. Here is a python routine which will open such a file and return a dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file) -> dict:\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files\n"
     ]
    }
   ],
   "source": [
    "path = 'Data\\CIFAR'\n",
    "files = glob.glob(os.path.join(path, '*_*'))\n",
    "print(\"Found \" + str(len(files)) + \" files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 1 big dictionary of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickling Data\\CIFAR\\data_batch_3\n",
      "Unpickling Data\\CIFAR\\data_batch_4\n",
      "Unpickling Data\\CIFAR\\data_batch_5\n",
      "Unpickling Data\\CIFAR\\data_batch_1\n",
      "Unpickling Data\\CIFAR\\data_batch_2\n",
      "# Classifications: 50000\n",
      "# Images: 50000\n",
      "# Filenames: 50000\n",
      "Shape of the image data-array: (50000, 3072)\n",
      "[[ 26  17  13 ...  27  26  27]\n",
      " [ 94 101  95 ... 182 184 155]\n",
      " [183 158 166 ... 250 250 250]\n",
      " ...\n",
      " [127 139 155 ... 197 192 191]\n",
      " [190 200 208 ... 163 182 192]\n",
      " [177 174 182 ... 119 127 136]]\n"
     ]
    }
   ],
   "source": [
    "data = {b'labels': [], b'data': np.empty([0,3072], dtype=np.uint8) , b'filenames': [] }\n",
    "\n",
    "for filename in files:\n",
    "    print(\"Unpickling \" + filename)\n",
    "    newData = unpickle(filename)\n",
    "    data[b'labels'].extend(newData[b'labels'])\n",
    "    data[b'data'] = np.append(data[b'data'], newData[b'data'], axis=0)\n",
    "    data[b'filenames'].extend(newData[b'filenames'])\n",
    "    \n",
    "print(\"# Classifications: \" + str(len(data[b'labels'])))\n",
    "print(\"# Images: \" + str(len(data[b'data'])))\n",
    "print(\"# Filenames: \" + str(len(data[b'filenames'])))\n",
    "\n",
    "print(\"Shape of the image data-array: \" + str(data[b'data'].shape))\n",
    "\n",
    "print(str(data[b'data']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dictionary for one file most importantly contains\n",
    "\n",
    "- **data:** a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. \n",
    "- **labels:** a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first image. It is gorgeous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = np.asarray(np.split(data[b'data'][0][0:1024], indices_or_sections=32))\n",
    "green = np.asarray(np.split(data[b'data'][0][1024:2048], indices_or_sections=32))\n",
    "blue = np.asarray(np.split(data[b'data'][0][2048:3072], indices_or_sections=32))\n",
    "redImage = Image.fromarray(red)\n",
    "greenImage = Image.fromarray(green)\n",
    "blueImage = Image.fromarray(blue)\n",
    "Image.merge('RGB', (redImage, greenImage, blueImage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the ground truth?\n",
    "\n",
    "The gound truth can be found in the ditctionary-item \"labels\". There are 50.000 classifications (as many as images) as numbers from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2, 5, 6, 6, 0, 9]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first 25 classes\n",
    "data[b'labels'][0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Classes: 10\n"
     ]
    }
   ],
   "source": [
    "classes_count = len(set(data[b'labels']))\n",
    "print(\"# Classes: \" + str(classes_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groundtruth Statistics:\n",
      "Class 0: 5000\n",
      "Class 1: 5000\n",
      "Class 2: 5000\n",
      "Class 3: 5000\n",
      "Class 4: 5000\n",
      "Class 5: 5000\n",
      "Class 6: 5000\n",
      "Class 7: 5000\n",
      "Class 8: 5000\n",
      "Class 9: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Groundtruth Statistics:\")\n",
    "\n",
    "for v in set(data[b'labels']):\n",
    "    print(\"Class \" + str(v) + \": \" + str(data[b'labels'].count(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "class_categories = np_utils.to_categorical(data[b'labels'])\n",
    "print(class_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "<b>Always standardize</b> the data before feeding it into the Neural Network!\n",
    "\n",
    "Here we use <b>Zero-mean Unit-variance standardization</b> which means we deduct the mean and divide by the standard deviation.\n",
    "\n",
    "(Note: Here, we do this \"flat\", i.e. one mean and std.dev. for the whole image is computed over all pixels (not per pixel); in RGB images, standardization can be done e.g. for each colour channel individually; in other/non-image data sets, attribute-wise standardization should be applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image values statistics:\n",
      "min pixel value: 0\n",
      "max pixel value: 255\n",
      "mean pixel value: 120.70756512369792\n",
      "standard deviation: 64.15007589112118\n",
      "Standardized image's mean: -2.7083520611389153e-17\n",
      "Standardized image's standard deviation: 0.9999999999999994\n",
      "Standardized image's min: -1.881643372153901\n",
      "Standardized image's max: 2.093410381995964\n"
     ]
    }
   ],
   "source": [
    "print(\"Image values statistics:\")\n",
    "print(\"min pixel value: \" + str(data[b'data'].min()))\n",
    "print(\"max pixel value: \" + str(data[b'data'].max()))\n",
    "\n",
    "mean = data[b'data'].mean()\n",
    "stddev = data[b'data'].std()\n",
    "\n",
    "print(\"mean pixel value: \" + str(mean))\n",
    "print(\"standard deviation: \" + str(stddev))\n",
    "\n",
    "standardized_images = (data[b'data'] - mean) / stddev\n",
    "print(\"Standardized image's mean: \" + str(standardized_images.mean()))\n",
    "print(\"Standardized image's standard deviation: \" + str(standardized_images.std()))\n",
    "\n",
    "print(\"Standardized image's min: \" + str(standardized_images.min()))\n",
    "print(\"Standardized image's max: \" + str(standardized_images.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47634377, -1.61663979, -1.67899357, ..., -1.46075533,\n",
       "        -1.47634377, -1.46075533],\n",
       "       [-0.41632944, -0.30721032, -0.40074099, ...,  0.95545382,\n",
       "         0.98663071,  0.53456577],\n",
       "       [ 0.97104226,  0.58133111,  0.70603868, ...,  2.01546815,\n",
       "         2.01546815,  2.01546815],\n",
       "       ...,\n",
       "       [ 0.09808928,  0.28515064,  0.53456577, ...,  1.18928051,\n",
       "         1.11133828,  1.09574983],\n",
       "       [ 1.08016139,  1.23604585,  1.36075342, ...,  0.65927334,\n",
       "         0.95545382,  1.11133828],\n",
       "       [ 0.87751159,  0.83074625,  0.95545382, ..., -0.02661829,\n",
       "         0.09808928,  0.2383853 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NN Models in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1) Fully Connected NN\n",
    "\n",
    "For a fully connected neural network, the x and y axis of an image do not play a role at all. All pixels are considered as a completely individual input to the neural network. Therefore the 2D image arrays have to be flattened to a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for NN: 3072\n"
     ]
    }
   ],
   "source": [
    "# find out input shape for NN, which is just a long vector (40x100 = 4000)\n",
    "input_shape = standardized_images.shape[1]\n",
    "print(\"Input shape for NN: \" + str(input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "In Keras, one can choose between a Sequential model and a Graph model. Sequential models are the standard case. Graph models are for parallel networks and use the functional API.\n",
    "\n",
    "Here we create a sequential model with 2 fully connected (a.k.a. 'dense') layers containing 256 units each.\n",
    "\n",
    "The output unit is a Single sigmoid unit which can predict values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple Fully-connected network\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(256, input_dim=input_shape))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dense(classes_count, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 256)               786688    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855,050\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss Function and Optimizer Strategy: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters globally for all subsequent models\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = 'sgd'\n",
    "metrics=['categorical_accuracy']\n",
    "batch_size=32\n",
    "epochs=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6945 - categorical_accuracy: 0.4093\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4419 - categorical_accuracy: 0.4960\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.3395 - categorical_accuracy: 0.5345\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2660 - categorical_accuracy: 0.5605\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.2060 - categorical_accuracy: 0.5831\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1530 - categorical_accuracy: 0.6017\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.1061 - categorical_accuracy: 0.6160\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.0613 - categorical_accuracy: 0.6334\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0211 - categorical_accuracy: 0.6475\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.9828 - categorical_accuracy: 0.6599\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9477 - categorical_accuracy: 0.6751\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9077 - categorical_accuracy: 0.6909\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8781 - categorical_accuracy: 0.6974\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8462 - categorical_accuracy: 0.7088\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8155 - categorical_accuracy: 0.7182\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "# This creates the whole model structure in memory. \n",
    "# If you use GPU computation, here GPU compatible structures and code is generated.\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "history = model.fit(standardized_images, class_categories, batch_size=batch_size, epochs=epochs) #, validation_data=validation_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "Accuracy Score of model: 0.7534\n"
     ]
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "predictions = model.predict(standardized_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Accuracy Score of model: \" + str(accuracy_score(np.array(data[b'labels']), predicted_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% Accuracy - perfect, no?\n",
    "\n",
    "This is the accuracy on the training set. A (large, especially fully connected network with sufficient number of units) can easily learn the entire training set (especially a small one like here).\n",
    "\n",
    "This very likely leads to <b>overfitting</b>. That's why we test on an independent test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset contains 10.000 images with their classifications (categories are the same as with the training set). They can be found in one file (test_batch). Each class consists of 1000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files\n"
     ]
    }
   ],
   "source": [
    "test_path = 'Data\\CIFAR\\Info'\n",
    "test_files = glob.glob(os.path.join(test_path, 'test_batch'))\n",
    "print(\"Found \" + str(len(test_files)) + \" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickling Data\\CIFAR\\Info\\test_batch\n",
      "# Classifications: 10000\n",
      "# Images: 10000\n",
      "# Filenames: 10000\n",
      "Shape of the image data-array: (10000, 3072)\n",
      "Groundtruth Statistics:\n",
      "Class 0: 1000\n",
      "Class 1: 1000\n",
      "Class 2: 1000\n",
      "Class 3: 1000\n",
      "Class 4: 1000\n",
      "Class 5: 1000\n",
      "Class 6: 1000\n",
      "Class 7: 1000\n",
      "Class 8: 1000\n",
      "Class 9: 1000\n"
     ]
    }
   ],
   "source": [
    "test_data = {b'labels': [], b'data': np.empty([0,3072], dtype=np.uint8) , b'filenames': [] }\n",
    "\n",
    "for filename in test_files:\n",
    "    print(\"Unpickling \" + filename)\n",
    "    newTestData = unpickle(filename)\n",
    "    test_data[b'labels'].extend(newTestData[b'labels'])\n",
    "    test_data[b'data'] = np.append(test_data[b'data'], newTestData[b'data'], axis=0)\n",
    "    test_data[b'filenames'].extend(newTestData[b'filenames'])\n",
    "    \n",
    "print(\"# Classifications: \" + str(len(test_data[b'labels'])))\n",
    "print(\"# Images: \" + str(len(test_data[b'data'])))\n",
    "print(\"# Filenames: \" + str(len(test_data[b'filenames'])))\n",
    "\n",
    "print(\"Shape of the image data-array: \" + str(test_data[b'data'].shape))\n",
    "\n",
    "print(\"Groundtruth Statistics:\")\n",
    "\n",
    "for v in set(test_data[b'labels']):\n",
    "    print(\"Class \" + str(v) + \": \" + str(test_data[b'labels'].count(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = np.asarray(np.split(test_data[b'data'][0][0:1024], indices_or_sections=32))\n",
    "green = np.asarray(np.split(test_data[b'data'][0][1024:2048], indices_or_sections=32))\n",
    "blue = np.asarray(np.split(test_data[b'data'][0][2048:3072], indices_or_sections=32))\n",
    "redImage = Image.fromarray(red)\n",
    "greenImage = Image.fromarray(green)\n",
    "blueImage = Image.fromarray(blue)\n",
    "Image.merge('RGB', (redImage, greenImage, blueImage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Test Set\n",
    "\n",
    "The test data has to be standardized <b>in the same way</b> as the training data for compatibility with the model! That means, we take the mean and standard deviation of the <i>training data</i> to transform also the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image values statistics:\n",
      "min pixel value: 0\n",
      "max pixel value: 255\n",
      "mean pixel value: 121.52915475260417\n",
      "standard deviation: 64.06097012299574\n",
      "Standardized image's mean: -8.459899447643693e-17\n",
      "Standardized image's standard deviation: 1.000000000000001\n",
      "Standardized image's min: -1.8970857687492197\n",
      "Standardized image's max: 2.083497096455682\n"
     ]
    }
   ],
   "source": [
    "print(\"Image values statistics:\")\n",
    "print(\"min pixel value: \" + str(test_data[b'data'].min()))\n",
    "print(\"max pixel value: \" + str(test_data[b'data'].max()))\n",
    "\n",
    "mean = test_data[b'data'].mean()\n",
    "stddev = test_data[b'data'].std()\n",
    "\n",
    "print(\"mean pixel value: \" + str(mean))\n",
    "print(\"standard deviation: \" + str(stddev))\n",
    "\n",
    "standardized_test_images = (test_data[b'data'] - mean) / stddev\n",
    "print(\"Standardized image's mean: \" + str(standardized_test_images.mean()))\n",
    "print(\"Standardized image's standard deviation: \" + str(standardized_test_images.std()))\n",
    "\n",
    "print(\"Standardized image's min: \" + str(standardized_test_images.min()))\n",
    "print(\"Standardized image's max: \" + str(standardized_test_images.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "Accuracy Score of model: 0.5272\n"
     ]
    }
   ],
   "source": [
    "# verify Accuracy on Test set\n",
    "test_predictions = model.predict(standardized_test_images)\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "print(\"Accuracy Score of model: \" + str(accuracy_score(np.array(test_data[b'labels']), test_predicted_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the Test Set is considerably lower compared to the accuracy of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "A Convolutional Neural Network (ConvNet or CNN) is a type of (deep) Neural Network that is well-suited for 2D axes data, such as images, as it is optimized for learning from spatial proximity. Its core elements are 2D filter kernels which essentially learn the weights of the Neural Network, and downscaling functions such as Max Pooling.\n",
    "\n",
    "A CNN can have one or more Convolution layers, each of them having an arbitrary number of N filters (which define the depth of the CNN layer), following typically by a pooling step, which groups neighboring pixels together and thus reduces the image resolution by retaining only the maximum values of neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "\n",
    "As with the model above, our input to the CNN is the standardized version of the original image array. We already have three chanels for the colors available in the training and test sets.\n",
    "\n",
    "We should deal with edge-pixels properly though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.47634377, -1.61663979, -1.67899357, ..., -1.46075533,\n",
       "       -1.47634377, -1.46075533])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = 3\n",
    "image_height = 32\n",
    "\n",
    "train_images = standardized_images.reshape(standardized_images.shape[0], image_height, image_height, channels)\n",
    "test_images = standardized_test_images.reshape(standardized_test_images.shape[0], image_height, image_height, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions training dataset: (50000, 3072)\n",
      "Dimensions testing dataset: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions training dataset: \" + str(standardized_images.shape))\n",
    "print(\"Dimensions testing dataset: \" + str(standardized_test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions training dataset reshaped: (50000, 32, 32, 3)\n",
      "Dimensions testing dataset reshaped: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions training dataset reshaped: \" + str(train_images.shape))\n",
    "print(\"Dimensions testing dataset reshaped: \" + str(test_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we store the new shape of the images in the 'input_shape' variable.\n",
    "# take all dimensions except the 0th one (which is the number of images)\n",
    "    \n",
    "input_shape = train_images.shape[1:]  \n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CNN model\n",
    "\n",
    "I have taken the model design from this source: https://www.tensorflow.org/tutorials/images/cnn\n",
    "It is designed to classify images from the CIFAR dataset as a tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createMyModel():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(input_shape[0] * 2, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(input_shape[0] * 2, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(input_shape[0] * 2, (3, 3), activation='relu'))\n",
    "    \n",
    "    # To complete the model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 64))\n",
    "    # into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), \n",
    "    # while the current output is a 3D tensor. First, you will flatten (or unroll) the 3D output to 1D, then add one\n",
    "    # or more Dense layers on top. CIFAR has 10 output classes, so you use a final Dense layer with 10 outputs.\n",
    "    # (Source: https://www.tensorflow.org/tutorials/images/cnn)\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,898\n",
      "Trainable params: 141,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = createMyModel()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you get OverflowError: Range exceeds valid bounds in the above box, check the correct Theano vs. Tensorflow ordering in the box before and your keras.json configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7803 - categorical_accuracy: 0.3591\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 38s 25ms/step - loss: 1.4543 - categorical_accuracy: 0.4830\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.3151 - categorical_accuracy: 0.5364\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.2173 - categorical_accuracy: 0.5726\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.1395 - categorical_accuracy: 0.6009\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.0766 - categorical_accuracy: 0.6238\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0263 - categorical_accuracy: 0.6416\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9776 - categorical_accuracy: 0.6592\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.9357 - categorical_accuracy: 0.6730\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.8960 - categorical_accuracy: 0.6854\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.8583 - categorical_accuracy: 0.6991\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.8254 - categorical_accuracy: 0.7114\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7875 - categorical_accuracy: 0.7267\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7552 - categorical_accuracy: 0.7352\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.7222 - categorical_accuracy: 0.7460\n"
     ]
    }
   ],
   "source": [
    "cnn_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "history = cnn_model.fit(train_images, class_categories, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick increase in accuracy and - after a few epochs - a stagnation in the gain of accuracy can be observed when training the model. However, as seen above, this accuracy must be considered with caution, since it probably will not perform as good on unseen (test) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n",
      "Accuracy Score of model: 0.6283\n"
     ]
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "predictions = cnn_model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Accuracy Score of model: \" + str(accuracy_score(np.array(test_data[b'labels']), predicted_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, the accuracy achieved with the test data is considerably lower than with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Training Curve\n",
    "\n",
    "The `model.fit` function returns a history including the evolution of training and validation loss and accuracy. We can plot it to see a nice training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'categorical_accuracy'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history = history.history\n",
    "training_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cd55fbb640>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {'loss':'r', 'categorical_accuracy':'b'}\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Training Curve\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "for measure in training_history.keys():\n",
    "    color = colors[measure]\n",
    "    plt.plot(range(1,15+1), training_history[measure], color + '-', label=measure)  # use last 2 values to draw line\n",
    "\n",
    "plt.legend(loc='upper left', scatterpoints = 1, frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Even though the accuracy of the training set can't be achieved entirely, the accuracy with the test set is not terribly lower. It is significat however and shows that the accuracy achieved with the training set must not be trusted blindly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Increase the training set by adding more images: Rotate, shift, flip and scale the original images to generate additional examples that will help the Neural Network to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ImageDataGenerator needs the classes as Numpy array instead of normal list\n",
    "np.array(test_data[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # enforce repeatable result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 2.0654 - categorical_accuracy: 0.2345\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.8870 - categorical_accuracy: 0.3035\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 1.8222 - categorical_accuracy: 0.3276\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7740 - categorical_accuracy: 0.3494\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.7345 - categorical_accuracy: 0.3660\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6900 - categorical_accuracy: 0.3848\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.6603 - categorical_accuracy: 0.3975\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.6262 - categorical_accuracy: 0.4114\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.6040 - categorical_accuracy: 0.4207\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5806 - categorical_accuracy: 0.4289\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.5583 - categorical_accuracy: 0.4394\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 1.5397 - categorical_accuracy: 0.4443\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.5234 - categorical_accuracy: 0.4525\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.5080 - categorical_accuracy: 0.4573\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 1.4941 - categorical_accuracy: 0.4624\n"
     ]
    }
   ],
   "source": [
    "# recreate and recompile the model (otherwise we continue learning)\n",
    "augmented_model = createMyModel()\n",
    "augmented_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = augmented_model.fit(datagen.flow(train_images, class_categories, batch_size=batch_size), batch_size=batch_size, epochs=epochs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set (with Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step\n",
      "Accuracy Score of model: 0.4546\n"
     ]
    }
   ],
   "source": [
    "# verify Accuracy on Train set\n",
    "predictions = augmented_model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Accuracy Score of model: \" + str(accuracy_score(np.array(test_data[b'labels']), predicted_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this instance, data augmentation did not achieve better accuracy values. This might be, because the images are too small for rotation and zoom to give any diversification in trainable images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting the Training Curve with Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cd59b39810>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Training Curve\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "for measure in hist.keys():\n",
    "    color = colors[measure]\n",
    "    plt.plot(range(1,epochs+1), hist[measure], color + '-', label=measure)  # use last 2 values to draw line\n",
    "\n",
    "plt.legend(loc='upper left', scatterpoints = 1, frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy does not increase as fast and stops considerably lower than with the un-augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "The CNN performs better than the fully connected NN. However, augmenting the training data does not imporove accuracy performance. The CIFAR images seem to be resistant to augmentation because of their small size and therefore low reolution. Training the models is rather fast. The CNN is considerably slower, but with only 50000 images, it is still reasonable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "14168f5bff84b5ed7e5e625d87137c837ac6ddab66f8b46da01ce5866a8afee8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
